{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/yk4we/SYS6016/fer2013_and_plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Usage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist() # 1\n",
    "\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face = np.asarray(face).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces.append(face.astype('float32'))\n",
    "\n",
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1) # 6\n",
    "\n",
    "# emotions = pd.get_dummies(data['emotion']).as_matrix() # 7\n",
    "emotions = pd.get_dummies(data['plus_emotion']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 5,905,863\n",
      "Trainable params: 5,902,151\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='/home/yk4we/SYS6016/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = '/home/yk4we/SYS6016/models/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(MODELPATH, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpointer]#lr_reducer, tensorboard, early_stopper, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29068 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 1.7958 - accuracy: 0.3320 - val_loss: 1.6111 - val_accuracy: 0.3667\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61112, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 2/100\n",
      "29068/29068 [==============================] - 557s 19ms/step - loss: 1.5815 - accuracy: 0.3830 - val_loss: 1.5748 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61112 to 1.57479, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 3/100\n",
      "29068/29068 [==============================] - 552s 19ms/step - loss: 1.4983 - accuracy: 0.4195 - val_loss: 1.5010 - val_accuracy: 0.3987\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.57479 to 1.50105, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 4/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 1.3898 - accuracy: 0.4745 - val_loss: 1.2715 - val_accuracy: 0.5274\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.50105 to 1.27150, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 5/100\n",
      "29068/29068 [==============================] - 560s 19ms/step - loss: 1.1925 - accuracy: 0.5992 - val_loss: 1.2085 - val_accuracy: 0.5907\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27150 to 1.20854, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 6/100\n",
      "29068/29068 [==============================] - 551s 19ms/step - loss: 1.0771 - accuracy: 0.6405 - val_loss: 1.0188 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20854 to 1.01880, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 7/100\n",
      "29068/29068 [==============================] - 552s 19ms/step - loss: 1.0073 - accuracy: 0.6646 - val_loss: 0.9700 - val_accuracy: 0.6615\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01880 to 0.97000, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 8/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 0.9527 - accuracy: 0.6797 - val_loss: 0.8592 - val_accuracy: 0.7069\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97000 to 0.85920, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 9/100\n",
      "29068/29068 [==============================] - 561s 19ms/step - loss: 0.9165 - accuracy: 0.6928 - val_loss: 0.8623 - val_accuracy: 0.7049\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.85920\n",
      "Epoch 10/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 0.8743 - accuracy: 0.7083 - val_loss: 0.8629 - val_accuracy: 0.7175\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.85920\n",
      "Epoch 11/100\n",
      "29068/29068 [==============================] - 553s 19ms/step - loss: 0.8533 - accuracy: 0.7177 - val_loss: 0.7683 - val_accuracy: 0.7386\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.85920 to 0.76826, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 12/100\n",
      "29068/29068 [==============================] - 551s 19ms/step - loss: 0.8195 - accuracy: 0.7253 - val_loss: 0.7545 - val_accuracy: 0.7256\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.76826 to 0.75449, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 13/100\n",
      "29068/29068 [==============================] - 553s 19ms/step - loss: 0.7901 - accuracy: 0.7353 - val_loss: 0.8071 - val_accuracy: 0.7233\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.75449\n",
      "Epoch 14/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 0.7577 - accuracy: 0.7487 - val_loss: 0.8784 - val_accuracy: 0.6935\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.75449\n",
      "Epoch 15/100\n",
      "29068/29068 [==============================] - 553s 19ms/step - loss: 0.7374 - accuracy: 0.7503 - val_loss: 0.7246 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.75449 to 0.72460, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 16/100\n",
      "29068/29068 [==============================] - 550s 19ms/step - loss: 0.7072 - accuracy: 0.7620 - val_loss: 0.7010 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.72460 to 0.70101, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 17/100\n",
      "29068/29068 [==============================] - 549s 19ms/step - loss: 0.6978 - accuracy: 0.7642 - val_loss: 0.6811 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70101 to 0.68105, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 18/100\n",
      "29068/29068 [==============================] - 552s 19ms/step - loss: 0.6687 - accuracy: 0.7748 - val_loss: 0.7016 - val_accuracy: 0.7529\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68105\n",
      "Epoch 19/100\n",
      "29068/29068 [==============================] - 553s 19ms/step - loss: 0.6414 - accuracy: 0.7833 - val_loss: 0.6587 - val_accuracy: 0.7740\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.68105 to 0.65870, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 20/100\n",
      "29068/29068 [==============================] - 553s 19ms/step - loss: 0.6163 - accuracy: 0.7923 - val_loss: 0.6829 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.65870\n",
      "Epoch 21/100\n",
      "29068/29068 [==============================] - 549s 19ms/step - loss: 0.5924 - accuracy: 0.7999 - val_loss: 0.6493 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.65870 to 0.64927, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 22/100\n",
      "29068/29068 [==============================] - 551s 19ms/step - loss: 0.5742 - accuracy: 0.8053 - val_loss: 0.6390 - val_accuracy: 0.7735\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.64927 to 0.63899, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 23/100\n",
      "29068/29068 [==============================] - 549s 19ms/step - loss: 0.5530 - accuracy: 0.8123 - val_loss: 0.7331 - val_accuracy: 0.7595\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.63899\n",
      "Epoch 24/100\n",
      "29068/29068 [==============================] - 550s 19ms/step - loss: 0.5453 - accuracy: 0.8182 - val_loss: 0.6261 - val_accuracy: 0.7882\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.63899 to 0.62610, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 25/100\n",
      "29068/29068 [==============================] - 552s 19ms/step - loss: 0.5230 - accuracy: 0.8240 - val_loss: 0.6231 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.62610 to 0.62308, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 26/100\n",
      "29068/29068 [==============================] - 551s 19ms/step - loss: 0.5155 - accuracy: 0.8257 - val_loss: 0.6119 - val_accuracy: 0.7938\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.62308 to 0.61188, saving model to /home/yk4we/SYS6016/models/model.h5\n",
      "Epoch 27/100\n",
      "29068/29068 [==============================] - 554s 19ms/step - loss: 0.4835 - accuracy: 0.8375 - val_loss: 0.6370 - val_accuracy: 0.7941\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.61188\n",
      "Epoch 28/100\n",
      "20416/29068 [====================>.........] - ETA: 2:39 - loss: 0.4750 - accuracy: 0.8397"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/yk4we/SYS6016/train.csv'\n",
    "image_size=(48,48)\n",
    " \n",
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data[['emotion']]).to_numpy()\n",
    "    return faces, emotions\n",
    " \n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    " \n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xtrain = xtrain.reshape(xtrain.shape[0], 48, 48, 1)\n",
    "xtrain = xtrain.astype('float32')\n",
    "xtest = xtest.reshape(xtest.shape[0], 48, 48, 1)\n",
    "xtest = xtest.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini_Xception Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 46, 46, 8)    72          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 46, 46, 8)    32          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 46, 46, 8)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 44, 44, 8)    576         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 44, 44, 8)    32          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 44, 44, 8)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_41 (SeparableC (None, 44, 44, 16)   200         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 44, 44, 16)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_42 (SeparableC (None, 44, 44, 16)   400         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 22, 22, 16)   128         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 22, 22, 16)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 22, 22, 16)   64          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 22, 22, 16)   0           max_pooling2d_29[0][0]           \n",
      "                                                                 batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_43 (SeparableC (None, 22, 22, 32)   656         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 22, 22, 32)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_44 (SeparableC (None, 22, 22, 32)   1312        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 11, 11, 32)   512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 11, 11, 32)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 11, 11, 32)   128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 11, 11, 32)   0           max_pooling2d_30[0][0]           \n",
      "                                                                 batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_45 (SeparableC (None, 11, 11, 64)   2336        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 11, 11, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_46 (SeparableC (None, 11, 11, 64)   4672        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 6, 6, 64)     2048        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 6, 6, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 64)     256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 6, 6, 64)     0           max_pooling2d_31[0][0]           \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_47 (SeparableC (None, 6, 6, 128)    8768        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_48 (SeparableC (None, 6, 6, 128)    17536       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 3, 3, 128)    8192        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, 3, 3, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 3, 3, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 3, 3, 128)    0           max_pooling2d_32[0][0]           \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 3, 3, 7)      8071        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 7)            0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected predictions to have shape (7,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-d6560f3ec68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                         validation_data=(np.array(xtest),np.array(ytest)))\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    148\u001b[0m                                      str(validation_data))\n\u001b[1;32m    149\u001b[0m                 val_x, val_y, val_sample_weights = model._standardize_user_data(\n\u001b[0;32m--> 150\u001b[0;31m                     val_x, val_y, val_sample_weight)\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 if model.uses_learning_phase and not isinstance(K.learning_phase(),\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected predictions to have shape (7,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 110\n",
    "input_shape = (48, 48, 1)\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '/home/yk4we/SYS6016/models'\n",
    "l2_regularization=0.01\n",
    " \n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    " \n",
    "# model parameters\n",
    "regularization = l2(l2_regularization)\n",
    " \n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    " \n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax',name='predictions')(x)\n",
    " \n",
    "model = Model(img_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "# callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "xtest.shape \n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(np.array(xtest),np.array(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-db67ddf25fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fer2013\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_path = '/home/yk4we/SYS6016/train.csv'\n",
    "image_size=(48,48)\n",
    " \n",
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion'])\n",
    "    print(type(emotions))\n",
    "    return faces, emotions\n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
